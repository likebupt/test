{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a simple ML pipeline for image classification\n",
    "\n",
    "**Requirements** - In order to benefit from this tutorial, you will need:\n",
    "- A basic understanding of Machine Learning\n",
    "- An Azure account with an active subscription. [Create an account for free](https://azure.microsoft.com/free/?WT.mc_id=A261C142F)\n",
    "- An Azure ML workspace. [Check this notebook for creating a workspace](/sdk/resources/workspace/workspace.ipynb) \n",
    "- A Compute Cluster. [Check this notebook to create a compute cluster](/sdk/resources/compute/compute.ipynb)\n",
    "- A python environment\n",
    "- Installed Azure Machine Learning Python SDK v2 - [install instructions](/sdk/README.md#getting-started)\n",
    "\n",
    "**Learning Objectives** - By the end of this tutorial, you should be able to:\n",
    "- Connect to your AML workspace from the Python SDK\n",
    "- Create `Pipeline` with components\n",
    "\n",
    "**Motivations** -This tutorial shows how to train a simple deep neural network using the [Fashion MNIST dataset and Keras on Azure Machine Learning. Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Connect to Azure Machine Learning Workspace\n",
    "\n",
    "The [workspace](https://docs.microsoft.com/en-us/azure/machine-learning/concept-workspace) is the top-level resource for Azure Machine Learning, providing a centralized place to work with all the artifacts you create when you use Azure Machine Learning. In this section we will connect to the workspace in which the job will be run.\n",
    "\n",
    "## 1.1. Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from azure.ml import MLClient, dsl\n",
    "from azure.ml.entities import load_component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Configure credential\n",
    "\n",
    "We are using `DefaultAzureCredential` to get access to workspace. When an access token is needed, it requests one using multiple identities(`EnvironmentCredential, ManagedIdentityCredential, SharedTokenCacheCredential, VisualStudioCodeCredential, AzureCliCredential, AzurePowerShellCredential`) in turn, stopping when one provides a token.\n",
    "Reference [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity.defaultazurecredential?view=azure-python) for more information.\n",
    "\n",
    "`DefaultAzureCredential` should be capable of handling most Azure SDK authentication scenarios. \n",
    "Reference [here](https://docs.microsoft.com/en-us/python/api/azure-identity/azure.identity?view=azure-python) for all available credentials if it does not work for you.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential(exclude_visual_studio_code_credential=True)\n",
    "    # Check if given credential can get token successfully.\n",
    "    credential.get_token('https://management.azure.com/.default')\n",
    "except Exception as ex:\n",
    "    # If exception happens when retrieve token, try exclude the failed credential like this then try again:\n",
    "    # Exclude VSCode credential:\n",
    "    # credential = DefaultAzureCredential(exclude_visual_studio_code_credential=True)\n",
    "    raise Exception(\"Failed to retrieve a token from the included credentials due to the following exception, try to add `exclude_xxx_credential=True` to `DefaultAzureCredential` and try again.\") from ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Configure workspace details and get a handle to the workspace\n",
    "\n",
    "To connect to a workspace, we need identifier parameters - a subscription, resource group and workspace name. We will use these details in the `MLClient` from `azure.ml` to get a handle to the required Azure Machine Learning workspace. `MLClient.from_config()` reads the file config.json and loads the details into an object named ml_client, and it expects the workspace configuration to be saved in the current directory or its parent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"./config.json\"\n",
    "ml_client = MLClient.from_config(credential=credential, path=config_path)\n",
    "print(ml_client)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Retrieve or create an Azure Machine Learning compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import AmlCompute\n",
    "\n",
    "# specify aml compute name.\n",
    "gpu_compute_target = 'gpu-cluster'\n",
    "cpu_compute_target = 'test-ci'\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(cpu_compute_target)\n",
    "except Exception:\n",
    "    print('Creating a new cpu compute target...')\n",
    "    compute = AmlCompute(name=cpu_compute_target, size=\"STANDARD_D2_V2\", min_instances=0, max_instances=4)\n",
    "    ml_client.compute.begin_create_or_update(compute)\n",
    "\n",
    "try:\n",
    "    ml_client.compute.get(gpu_compute_target)\n",
    "except Exception:\n",
    "    print('Creating a new gpu compute target...')\n",
    "    compute = AmlCompute(name=gpu_compute_target, size=\"STANDARD_NC6\", min_instances=0, max_instances=4)\n",
    "    ml_client.compute.begin_create_or_update(compute)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Prepare Job Input\n",
    "By creating a dataset, you create a reference to the data source location. If you applied any subsetting transformations to the dataset, they will be stored in the dataset as well. The data remains in its existing location, so no extra storage cost is incurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ml.entities import JobInput\n",
    "\n",
    "fashion_ds = JobInput(path=\"wasbs://demo@data4mldemo6150520719.blob.core.windows.net/mnist-fashion/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure preparation step\n",
    "Using dsl component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'CliV2AnonymousEnvironment' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'CliV2AnonymousEnvironment' will not be used for anonymous registration\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Help on function prep in module prep.prep_dsl_component:\n",
      "\n",
      "prep(input_data: azure.ml.dsl._types.ArtifactInput, training_data: azure.ml.dsl._types.ArtifactOutput, test_data: azure.ml.dsl._types.ArtifactOutput)\n",
      "\n",
      "Help on function keras_train in module train.train_dsl_component:\n",
      "\n",
      "keras_train(input_data: azure.ml.dsl._types.ArtifactInput, output_model: azure.ml.dsl._types.ArtifactOutput, epochs=10)\n",
      "\n",
      "Help on CommandComponent in module azure.ml.entities._component.command_component object:\n",
      "\n",
      "class CommandComponent(azure.ml.entities._component.component.Component, azure.ml.entities._job.parameterized_command.ParameterizedCommand)\n",
      " |  CommandComponent(*, name: str = None, version: str = None, description: str = None, tags: Dict = None, display_name: str = None, command: str = None, code: str = None, environment: Union[str, azure.ml.entities._assets.environment.Environment] = None, distribution: Union[azure.ml._restclient.v2022_02_01_preview.models._models_py3.PyTorch, azure.ml._restclient.v2022_02_01_preview.models._models_py3.Mpi, azure.ml._restclient.v2022_02_01_preview.models._models_py3.TensorFlow] = None, resources: azure.ml.entities._job.resource_configuration.ResourceConfiguration = None, inputs: Dict = None, outputs: Dict = None, instance_count: int = None, **kwargs)\n",
      " |  \n",
      " |  Command component version, used to define an command component.\n",
      " |  \n",
      " |  :param name: Name of the component.\n",
      " |  :type name: str\n",
      " |  :param version: Version of the component.\n",
      " |  :type version: str\n",
      " |  :param id:  Global id of the resource, Azure Resource Manager ID.\n",
      " |  :type id: str\n",
      " |  :param type:  Type of the component, supported is 'command_component'.\n",
      " |  :type type: str\n",
      " |  :param description: Description of the component.\n",
      " |  :type description: str\n",
      " |  :param tags: Internal use only.\n",
      " |  :type tags: dict\n",
      " |  :param properties: Internal use only.\n",
      " |  :type properties: dict\n",
      " |  :param display_name: Display name of the component.\n",
      " |  :type display_name: str\n",
      " |  :param is_deterministic: Whether the component is deterministic. The default is True.\n",
      " |  :type is_deterministic: bool\n",
      " |  :param inputs: Inputs of the component.\n",
      " |  :type inputs: dict\n",
      " |  :param outputs: Outputs of the component.\n",
      " |  :type outputs: dict\n",
      " |  :param command: Command to be executed in component.\n",
      " |  :type command: str\n",
      " |  :param code: Code file or folder that will be uploaded to the cloud for component execution.\n",
      " |  :type code: str\n",
      " |  :param environment: Environment that component will run in.\n",
      " |  :type environment: Union[Environment, str]\n",
      " |  :param resources: Compute Resource configuration for the component.\n",
      " |  :type resources: Union[Dict, ~azure.ml.entities.ResourceConfiguration]\n",
      " |  :param distribution: Distribution configuration for distributed training.\n",
      " |  :type distribution: Union[Dict, PyTorch, Mpi, TensorFlow]\n",
      " |  :param instance_count: promoted property from resources.instance_count\n",
      " |  :type instance_count: int\n",
      " |  :param creation_context: Creation metadata of the component.\n",
      " |  :type creation_context: SystemData\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      CommandComponent\n",
      " |      azure.ml.entities._component.component.Component\n",
      " |      azure.ml.entities._assets.asset.Asset\n",
      " |      azure.ml.entities._resource.Resource\n",
      " |      abc.ABC\n",
      " |      azure.ml.entities._mixins.RestTranslatableMixin\n",
      " |      azure.ml.entities._mixins.YamlTranslatableMixin\n",
      " |      azure.ml.entities._job.parameterized_command.ParameterizedCommand\n",
      " |      azure.ml._schema.job.loadable_mixin.LoadableMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, name: str = None, version: str = None, description: str = None, tags: Dict = None, display_name: str = None, command: str = None, code: str = None, environment: Union[str, azure.ml.entities._assets.environment.Environment] = None, distribution: Union[azure.ml._restclient.v2022_02_01_preview.models._models_py3.PyTorch, azure.ml._restclient.v2022_02_01_preview.models._models_py3.Mpi, azure.ml._restclient.v2022_02_01_preview.models._models_py3.TensorFlow] = None, resources: azure.ml.entities._job.resource_configuration.ResourceConfiguration = None, inputs: Dict = None, outputs: Dict = None, instance_count: int = None, **kwargs)\n",
      " |      Class Resource constructor.\n",
      " |      \n",
      " |      :param name: Name of the resource.\n",
      " |      :type name: str\n",
      " |      :param description: Description of the resource., defaults to None\n",
      " |      :type description: str, optional\n",
      " |      :param tags: Tag dictionary. Tags can be added, removed, and updated., defaults to None\n",
      " |      :type tags: Dict, optional\n",
      " |      :param properties: The asset property dictionary., defaults to None\n",
      " |      :type properties: Dict, optional\n",
      " |      :param kwargs: A dictionary of additional configuration parameters.\n",
      " |      :type kwargs: dict\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  instance_count\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from azure.ml.entities._component.component.Component:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs) -> [Ellipsis, ForwardRef('Command')]\n",
      " |      Call ComponentVersion as a function and get a Component object.\n",
      " |  \n",
      " |  dump(self, path: Union[os.PathLike, str]) -> None\n",
      " |      Dump the component content into a file in yaml format.\n",
      " |      \n",
      " |      :param path: Path to a local file as the target, new file will be created, raises exception if the file exists.\n",
      " |      :type path: str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from azure.ml.entities._component.component.Component:\n",
      " |  \n",
      " |  load(path: Union[os.PathLike, str], params_override: list = None, **kwargs) -> 'Component' from abc.ABCMeta\n",
      " |      Construct a component object from a yaml file.\n",
      " |      \n",
      " |      :param path: Path to a local file as the source.\n",
      " |      :type path: str\n",
      " |      :param params_override: Fields to overwrite on top of the yaml file. Format is [{\"field1\": \"value1\"}, {\"field2\": \"value2\"}]\n",
      " |      :type params_override: list\n",
      " |      :param kwargs: A dictionary of additional configuration parameters.\n",
      " |      :type kwargs: dict\n",
      " |      \n",
      " |      :return: Loaded component object.\n",
      " |      :rtype: component\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from azure.ml.entities._component.component.Component:\n",
      " |  \n",
      " |  auto_increment_version\n",
      " |  \n",
      " |  display_name\n",
      " |      Display name of the component.\n",
      " |      \n",
      " |      :return: Display name of the component.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  inputs\n",
      " |      Inputs of the component.\n",
      " |      \n",
      " |      :return: Inputs of the component.\n",
      " |      :rtype: dict\n",
      " |  \n",
      " |  is_deterministic\n",
      " |      Whether the component is deterministic.\n",
      " |      \n",
      " |      :return: Whether the component is deterministic\n",
      " |      :rtype: bool\n",
      " |  \n",
      " |  outputs\n",
      " |      Outputs of the component.\n",
      " |      \n",
      " |      :return: Outputs of the component.\n",
      " |      :rtype: dict\n",
      " |  \n",
      " |  type\n",
      " |      Type of the component, supported is 'command'.\n",
      " |      \n",
      " |      :return: Type of the component.\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  version\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from azure.ml.entities._component.component.Component:\n",
      " |  \n",
      " |  CODE_GEN_BY_KEY = 'codegenBy'\n",
      " |  \n",
      " |  DSL_COMPONENT = 'dsl.component'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from azure.ml.entities._assets.asset.Asset:\n",
      " |  \n",
      " |  __eq__(self, other) -> bool\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __ne__(self, other) -> bool\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from azure.ml.entities._assets.asset.Asset:\n",
      " |  \n",
      " |  __hash__ = None\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from azure.ml.entities._resource.Resource:\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from azure.ml.entities._resource.Resource:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  base_path\n",
      " |      Base path of the resource\n",
      " |      \n",
      " |      :return: Base path of the resource\n",
      " |      :rtype: str\n",
      " |  \n",
      " |  creation_context\n",
      " |      Creation context\n",
      " |      \n",
      " |      :return: Creation metadata of the resource.\n",
      " |      :rtype: Optional[SystemData]\n",
      " |  \n",
      " |  id\n",
      " |      Resource ID.\n",
      " |      \n",
      " |      :return: Global id of the resource, Azure Resource Manager ID\n",
      " |      :rtype: Optional[str]\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from azure.ml.entities._job.parameterized_command.ParameterizedCommand:\n",
      " |  \n",
      " |  distribution\n",
      " |  \n",
      " |  resources\n",
      "\n",
      "$schema: '{}'\n",
      "type: command\n",
      "inputs: {}\n",
      "outputs: {}\n",
      "command: python -m azure.ml.dsl.executor --file prep_dsl_component.py --name prep_data\n",
      "  --params --input_data ${{inputs.input_data}} --training_data ${{outputs.training_data}}\n",
      "  --test_data ${{outputs.test_data}}\n",
      "code: d:/Github/test/2e_image_classification_keras_minist_convnet/prep\n",
      "environment_variables: {}\n",
      "component:\n",
      "  name: prep_data\n",
      "  version: '1'\n",
      "  display_name: Prep Data\n",
      "  description: Convert data to CSV file, and split to training and test data\n",
      "  type: command\n",
      "  inputs:\n",
      "    input_data:\n",
      "      type: uri_folder\n",
      "  outputs:\n",
      "    training_data:\n",
      "      type: uri_folder\n",
      "    test_data:\n",
      "      type: uri_folder\n",
      "  command: python -m azure.ml.dsl.executor --file prep_dsl_component.py --name prep_data\n",
      "    --params --input_data ${{inputs.input_data}} --training_data ${{outputs.training_data}}\n",
      "    --test_data ${{outputs.test_data}}\n",
      "  environment:\n",
      "    name: CliV2AnonymousEnvironment\n",
      "    tags: {}\n",
      "    version: 0fc5c9eaf3b27f7547c25ed73b15ddd0\n",
      "    image: mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04\n",
      "    conda_file:\n",
      "      name: imagekeras_train_conda_env\n",
      "      channels:\n",
      "      - defaults\n",
      "      dependencies:\n",
      "      - python=3.7.11\n",
      "      - pip=20.0\n",
      "      - pip:\n",
      "        - --extra-index-url=https://azuremlsdktestpypi.azureedge.net/test-sdk-cli-v2\n",
      "        - azure-ml==0.0.59355733\n",
      "        - azureml-mlflow\n",
      "        - tensorflow==2.7.0\n",
      "        - numpy==1.21.4\n",
      "        - scikit-learn==1.0.1\n",
      "        - pandas==1.3.4\n",
      "        - matplotlib==3.2.2\n",
      "  code: azureml:d:/Github/test/2e_image_classification_keras_minist_convnet/prep\n",
      "  is_deterministic: true\n",
      "  tags:\n",
      "    codegenBy: dsl.component\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# If you modify the componetn source code, use following code to reload it\n",
    "# Otherwise notebook has cache and may not load the latest update\n",
    "import importlib, prep.prep_dsl_component, train.train_dsl_component\n",
    "importlib.reload(prep.prep_dsl_component)\n",
    "importlib.reload(train.train_dsl_component)\n",
    "\n",
    "# load component function from dsl component python file\n",
    "from prep.prep_dsl_component import prep\n",
    "from train.train_dsl_component import keras_train\n",
    "\n",
    "# load component function from yaml\n",
    "keras_score = load_component(yaml_file='./score/score.yaml')\n",
    "\n",
    "help(prep)\n",
    "help(keras_train)\n",
    "help(keras_score)\n",
    "print(prep())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prep node\n",
    "@dsl.pipeline(\n",
    "    display_name='test-prep-step',\n",
    "    description='E2E image classification pipeline with keras',\n",
    "    default_compute=cpu_compute_target,\n",
    ")\n",
    "def image_classification_keras_minist_convnet():\n",
    "\n",
    "    prepare_data_node = prep(input_data=fashion_ds)\n",
    "\n",
    "    train_node = keras_train(input_data=prepare_data_node.outputs.training_data)\n",
    "    train_node.compute = gpu_compute_target\n",
    "\n",
    "    score_node = keras_score(input_data=prepare_data_node.outputs.test_data, input_model=train_node.outputs.output_model)\n",
    "\n",
    "# create a pipeline\n",
    "pipeline = image_classification_keras_minist_convnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elated_pea_py0r2j7zwm\n"
     ]
    }
   ],
   "source": [
    "print(pipeline.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: the provided asset name 'CliV2AnonymousEnvironment' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'CliV2AnonymousEnvironment' will not be used for anonymous registration\n",
      "Warning: the provided asset name 'CliV2AnonymousEnvironment' will not be used for anonymous registration\n",
      "\u001b[32mUploading score (0.0 MBs): 100%|##########| 4633/4633 [00:01<00:00, 3855.24it/s]\n",
      "\u001b[39m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Name</th><th>Type</th><th>Status</th><th>Details Page</th></tr><tr><td>test-tutorials</td><td>careful_spinach_l9ntzmp2gr</td><td>pipeline</td><td>Preparing</td><td><a href=\"https://ml.azure.com/runs/careful_spinach_l9ntzmp2gr?wsid=/subscriptions/d128f140-94e6-4175-87a7-954b9d27db16/resourcegroups/ModuleX-rg/workspaces/shiyuws-canary&amp;tid=72f988bf-86f1-41af-91ab-2d7cd011db47\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td></tr></table>"
      ],
      "text/plain": [
       "PipelineJob({'inputs': {}, 'outputs': {}, 'component': _PipelineComponent({'components': {}, 'auto_increment_version': False, 'is_anonymous': True, 'name': '4e1e7e11-26fd-4e22-b5a5-36d28837c494', 'description': None, 'tags': {}, 'properties': {}, 'id': None, 'base_path': None, 'creation_context': None, 'serialize': <msrest.serialization.Serializer object at 0x0000026A8CE4F248>, 'version': '1', 'latest_version': None, 'schema': None, 'type': 'pipeline_component', 'display_name': None, 'is_deterministic': True, 'inputs': {}, 'outputs': {}, 'yaml_str': None, 'other_parameter': {}, 'func': <function [component] None at 0x0000026A8CFC3C18>}), 'display_name': 'careful_spinach_l9ntzmp2gr', 'type': 'pipeline', 'status': 'Preparing', 'log_files': None, 'name': 'careful_spinach_l9ntzmp2gr', 'description': None, 'tags': {}, 'properties': {'mlflow.source.git.repoURL': 'https://github.com/likebupt/test.git', 'mlflow.source.git.branch': 'main', 'mlflow.source.git.commit': '5c83841a4320172ba3f368325f3b1d4e487a194b', 'azureml.git.dirty': 'True', 'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDKv2', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.continue_on_step_failure': 'False', 'azureml.pipelineComponent': 'pipelinerun'}, 'id': '/subscriptions/d128f140-94e6-4175-87a7-954b9d27db16/resourceGroups/ModuleX-rg/providers/Microsoft.MachineLearningServices/workspaces/shiyuws-canary/jobs/careful_spinach_l9ntzmp2gr', 'base_path': './', 'creation_context': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.SystemData object at 0x0000026A8BB97648>, 'serialize': <msrest.serialization.Serializer object at 0x0000026A8B819388>, 'experiment_name': 'test-tutorials', 'compute': 'test-ci', 'services': {'Tracking': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x0000026A8CDF5048>, 'Studio': <azure.ml._restclient.v2022_02_01_preview.models._models_py3.JobService object at 0x0000026A8CDF5348>}, 'jobs': {'prepare_data_node': {'code': {}, 'command': {}}, 'train_node': {'code': {}, 'command': {}}, 'score_node': {'code': {}, 'command': {}}}, 'settings': <azure.ml.entities._job.pipeline.pipeline_job_settings.PipelineJobSettings object at 0x0000026A8CD095C8>, 'identity': None, 'default_code': None, 'default_environment': None})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_job = ml_client.jobs.create_or_update(pipeline, experiment_name='test-tutorials')\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define command component via YAML\n",
    "Below is a basic example to define command component  using YAML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset = load_component(yaml_file='./keras-mnist-fashion/prepare.yaml')\n",
    "train_model = load_component(yaml_file='./keras-mnist-fashion/train.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic pipeline job\n",
    "\n",
    "## 3.1 Build pipeline\n",
    "\n",
    "In step one, we will load the image and labels from Fashion MNIST dataset into mnist_train.csv and mnist_test.csv. Then in step two, train CNN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "@dsl.pipeline(\n",
    "    display_name='image_classification_keras_minist_convnet',\n",
    "    description='E2E image classification pipeline with keras',\n",
    "    default_compute=cpu_compute_target,\n",
    ")\n",
    "def image_classification_keras_minist_convnet():\n",
    "    prepare_dataset_node = prepare_dataset(input_path=fashion_ds)\n",
    "\n",
    "    train_node = (input_path=prepare_dataset_node.outputs.output_path)\n",
    "    train_node.compute = gpu_compute_target\n",
    "    \n",
    "    # Return: pipeline outputs\n",
    "    return {\n",
    "        \"trained_model\": train_node.outputs.output_model,\n",
    "    }\n",
    "\n",
    "# create a pipeline\n",
    "pipeline = image_classification_keras_minist_convnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2 Submit pipeline job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_job = ml_client.jobs.create_or_update(pipeline, experiment_name='pipeline_samples')\n",
    "pipeline_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait until the job completes\n",
    "ml_client.jobs.stream(pipeline_job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "You can see further examples of running a pipeline job [here](/sdk/jobs/pipelines/)"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create pipeline to train cnn image classification model with keras"
  },
  "interpreter": {
   "hash": "76e3f79dcda5ecc398e236cf994607053e7cf1e1f5da39c151cd830d8fe26160"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 ('chenyinpy38_v2_feb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
